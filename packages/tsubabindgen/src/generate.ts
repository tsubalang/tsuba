import { spawnSync } from "node:child_process";
import {
  cpSync,
  existsSync,
  mkdirSync,
  readFileSync,
  readdirSync,
  rmSync,
  statSync,
  writeFileSync,
} from "node:fs";
import { basename, dirname, join, relative, resolve } from "node:path";
import { fileURLToPath } from "node:url";

const MANIFEST_TEMPLATE = `// Generated by tsubabindgen (v0)
throw new Error("This package is type-only and intended to be compiled by Tsuba, not executed in Node.");
`;

const MARKER_TYPES = new Set([
  "bool",
  "f16",
  "bf16",
  "f32",
  "f64",
  "i8",
  "i16",
  "i32",
  "i64",
  "i128",
  "isize",
  "u8",
  "u16",
  "u32",
  "u64",
  "u128",
  "usize",
  "String",
  "Str",
  "Slice",
  "ArrayN",
  "Option",
  "Result",
  "ref",
  "mutref",
  "refLt",
  "mutrefLt",
  "mut",
  "Tokens",
  "Attr",
  "DeriveMacro",
  "Macro",
]);

const JS_KEYWORDS = new Set([
  "class",
  "delete",
  "default",
  "namespace",
  "return",
  "new",
  "super",
  "static",
  "var",
  "const",
  "let",
]);

export type GenerateOptions = {
  readonly manifestPath: string;
  readonly outDir: string;
  readonly packageName?: string;
  readonly bundleCrate: boolean;
};

export type GenerateBindings = {
  readonly schema: number;
  readonly kind: "crate";
  readonly crate: {
    readonly name: string;
    readonly package: string;
    readonly version?: string;
    readonly path?: string;
  };
  readonly modules: Record<string, string>;
};

type RustType = string;

type RustField = {
  readonly kind: "field";
  readonly name: string;
  readonly type: RustType;
};

type RustFunction = {
  readonly name: string;
  readonly typeParams: readonly string[];
  readonly params: readonly RustField[];
  readonly returnType: RustType;
};

type RustMethodKind = "constructor" | "instance" | "static";

type RustMethod = {
  readonly name: string;
  readonly kind: RustMethodKind;
  readonly typeParams: readonly string[];
  readonly params: readonly RustField[];
  readonly returnType: RustType;
};

type RustTraitMethod = {
  readonly name: string;
  readonly typeParams: readonly string[];
  readonly params: readonly RustField[];
  readonly returnType: RustType;
};

type RustTrait = {
  readonly name: string;
  readonly typeParams: readonly string[];
  readonly superTraits: readonly RustType[];
  readonly methods: readonly RustTraitMethod[];
};

type RustReexport = {
  readonly name: string;
  readonly source: string;
};

type RustStruct = {
  readonly name: string;
  readonly typeParams: readonly string[];
  readonly fields: readonly RustField[];
  methods: RustMethod[];
  constructorMethod?: RustMethod;
};

type RustEnum = {
  readonly name: string;
  readonly typeParams: readonly string[];
  readonly variants: readonly string[];
};

type ParsedModule = {
  specName: string;
  readonly source: string;
  moduleParts: string[];
  readonly consts: RustField[];
  enums: RustEnum[];
  structs: RustStruct[];
  traits: RustTrait[];
  functions: RustFunction[];
  reexports: RustReexport[];
  pendingMethods: Map<string, RustFunction[]>;
  issues: SkipIssue[];
};

type ExtractedPendingMethods = {
  readonly target: string;
  readonly methods: readonly RustFunction[];
};

type ExtractedModule = {
  readonly file: string;
  readonly parts: readonly string[];
  readonly consts: readonly RustField[];
  readonly enums: readonly RustEnum[];
  readonly structs: readonly RustStruct[];
  readonly traits: readonly RustTrait[];
  readonly functions: readonly RustFunction[];
  readonly reexports?: readonly {
    readonly name: string;
    readonly source: string;
  }[];
  readonly pendingMethods: readonly ExtractedPendingMethods[];
  readonly issues: readonly SkipIssue[];
};

type ExtractedOutput = {
  readonly schema: number;
  readonly modules: readonly ExtractedModule[];
};

type SkipIssue = {
  readonly file: string;
  readonly kind: string;
  readonly snippet: string;
  readonly reason: string;
};

function fail(message: string): never {
  throw new Error(message);
}

function normalizePath(path: string): string {
  return path.replaceAll("\\", "/");
}

function ensureDir(path: string): void {
  mkdirSync(path, { recursive: true });
}

function copyDir(src: string, dst: string): void {
  ensureDir(dst);
  for (const entry of readdirSync(src)) {
    if (entry === ".git" || entry === "target") continue;
    const from = join(src, entry);
    const to = join(dst, entry);
    const st = statSync(from);
    if (st.isDirectory()) {
      copyDir(from, to);
      continue;
    }
    cpSync(from, to);
  }
}

function normalizeTypeText(raw: string): string {
  return raw.trim().replaceAll(/\s+/g, " ");
}

function normalizeIdentifier(raw: string): string {
  const trimmed = raw.trim();
  return JS_KEYWORDS.has(trimmed) ? `${trimmed}_` : trimmed;
}

function parseGenericParamNames(raw: string, file: string, issues: SkipIssue[]): string[] {
  const out: string[] = [];
  for (const entry0 of splitTopLevel(raw, ",")) {
    const entry = entry0.trim();
    if (entry.length === 0) continue;
    if (entry.startsWith("'")) {
      issues.push({
        file,
        kind: "generic",
        snippet: entry,
        reason: "Rust lifetime generic parameters are not representable in TS facades and were skipped.",
      });
      continue;
    }
    const noConst = entry.startsWith("const ") ? entry.slice("const ".length).trim() : entry;
    if (entry.startsWith("const ")) {
      issues.push({
        file,
        kind: "generic",
        snippet: entry,
        reason: "Rust const generic parameters are not representable in TS facades and were skipped.",
      });
    }
    const [lhs] = noConst.split(":");
    const [namePart] = (lhs ?? noConst).split("=");
    const name = normalizeIdentifier((namePart ?? "").trim());
    if (!/^[A-Za-z_][A-Za-z0-9_]*$/.test(name)) {
      issues.push({
        file,
        kind: "generic",
        snippet: entry,
        reason: "Unsupported generic parameter syntax.",
      });
      continue;
    }
    out.push(name);
  }
  return out;
}

function stripCommentsAndAttrs(text: string): string {
  return text
    .replace(/\/\*[\s\S]*?\*\//g, "")
    .replace(/\/\/.*(?=[\n\r]|$)/g, "")
    .replace(/^\s*#\[[^\]\n]*\]\s*$/gm, "");
}

function splitTopLevel(text: string, sep: string): string[] {
  const out: string[] = [];
  let depth = 0;
  let quote: string | null = null;
  let start = 0;
  for (let i = 0; i < text.length; i += 1) {
    const ch = text[i]!;
    if (quote !== null) {
      if (ch === quote && text[i - 1] !== "\\") quote = null;
      continue;
    }
    if (ch === `"` || ch === "'" || ch === "`") {
      quote = ch;
      continue;
    }
    if (ch === "<" || ch === "(" || ch === "[" || ch === "{") {
      depth += 1;
      continue;
    }
    if (ch === ">" || ch === ")" || ch === "]" || ch === "}") {
      if (depth > 0) depth -= 1;
      continue;
    }
    if (depth === 0 && ch === sep) {
      const seg = text.slice(start, i).trim();
      if (seg.length > 0) out.push(seg);
      start = i + 1;
    }
  }
  const tail = text.slice(start).trim();
  if (tail.length > 0) out.push(tail);
  return out;
}

function findMatching(text: string, openAt: number, open: string, close: string): number {
  let depth = 0;
  let quote: string | null = null;
  for (let i = openAt; i < text.length; i += 1) {
    const ch = text[i]!;
    if (quote !== null) {
      if (ch === quote && text[i - 1] !== "\\") quote = null;
      continue;
    }
    if (ch === `"` || ch === "'" || ch === "`") {
      quote = ch;
      continue;
    }
    if (ch === open) {
      depth += 1;
      continue;
    }
    if (ch === close) {
      depth -= 1;
      if (depth === 0) return i;
    }
  }
  return -1;
}

function isSelfLike(name: string): boolean {
  return name === "self" || name === "&self" || name === "&mut self";
}

function parseType(raw: string, file: string, issues: SkipIssue[]): RustType {
  const withoutRhs = raw.split("=").map((part) => part.trim())[0] ?? raw;
  const text = normalizeTypeText(withoutRhs);
  if (text === "()" || text.length === 0) return "void";
  const open = text.indexOf("<");
  const close = text.lastIndexOf(">");
  if (open >= 0 && close > open && close === text.length - 1) {
    const base = text.slice(0, open).trim();
    const generic = text.slice(open + 1, close);
    const args = splitTopLevel(generic, ",").filter((s) => s.length > 0);
    const mappedArgs = args.map((arg) => parseType(arg, file, issues));
    const baseText = parseType(base, file, issues);
    if (base === "Vec") return `${mappedArgs[0] ?? "void"}[]`;
    if (base === "Option") return `Option<${mappedArgs[0] ?? "void"}>`;
    if (base === "Result") return `Result<${mappedArgs[0] ?? "void"}, ${mappedArgs[1] ?? "void"}>`;
    if (base === "Slice") return `Slice<${mappedArgs[0] ?? "void"}>`;
    if (base === "ArrayN") return `ArrayN<${mappedArgs[0] ?? "void"}, ${mappedArgs[1] ?? "0"}>`;
    if (base.startsWith("mutref") || base.startsWith("ref")) {
      return `${baseText}<${mappedArgs.join(", ")}>`;
    }
    return `${normalizeIdentifier(baseText)}<${mappedArgs.join(", ")}>`;
  }

  if (/^&\s*'/.test(text)) {
    const m = /^&\s*'([A-Za-z_][A-Za-z0-9_]*)\s+mut\s+(.+)$/s.exec(text);
    if (m?.[1] && m[2]) return `mutrefLt<"${m[1]}", ${parseType(m[2], file, issues)}>`;
    const n = /^&\s*'([A-Za-z_][A-Za-z0-9_]*)\s+(.+)$/s.exec(text);
    if (n?.[1] && n[2]) return `refLt<"${n[1]}", ${parseType(n[2], file, issues)}>`;
  }
  if (text.startsWith("&mut ")) return `mutref<${parseType(text.slice(5), file, issues)}>`;
  if (text.startsWith("&")) return `ref<${parseType(text.slice(1), file, issues)}>`;
  if (text.startsWith("'")) return text;
  if (text === "Self") return "Self";
  if (text.startsWith("[") && text.endsWith("]")) {
    const inner = text.slice(1, -1);
    const semi = inner.lastIndexOf(";");
    if (semi !== -1) {
      const item = inner.slice(0, semi).trim();
      const len = inner.slice(semi + 1).trim();
      if (len.length > 0) {
        if (/^[0-9]+$/u.test(len)) return `ArrayN<${parseType(item, file, issues)}, ${len}>`;
        issues.push({
          file,
          kind: "type",
          snippet: text,
          reason:
            "Array length uses a const expression/generic that is not representable in TS facades; using number.",
        });
        return `ArrayN<${parseType(item, file, issues)}, number>`;
      }
      return "void";
    }
  }
  if (text === "str") return "Str";
  if (text.includes("::")) {
    const parts = text.split("::").filter((s) => s.length > 0);
    return normalizeIdentifier(parts[parts.length - 1] ?? "void");
  }
  if (text.includes(" ")) {
    const compact = text.replace(/\s+/g, " ");
    if (compact.includes(" "))
      issues.push({
        file,
        kind: "type",
        snippet: text,
        reason: "Spaces in type expression could not be resolved safely; falling back to unknown.",
      });
    return "unknown";
  }
  return normalizeIdentifier(text);
}

function parseParams(raw: string, file: string, issues: SkipIssue[]): RustField[] {
  const body = normalizeTypeText(raw);
  if (!body) return [];
  const parts = splitTopLevel(body, ",");
  return parts.map((entry): RustField => {
    const segment = entry.trim();
    if (segment === "&self" || segment === "&mut self" || segment === "self") {
      return { kind: "field", name: segment, type: "self" };
    }
    const idx = segment.indexOf(":");
    if (idx === -1) {
      issues.push({
        file,
        kind: "param",
        snippet: segment,
        reason: "Non-standard function parameter syntax (expected name: type).",
      });
      return { kind: "field", name: "unsupported", type: "unknown" };
    }
    const name = segment.slice(0, idx).trim();
    const type = segment.slice(idx + 1).trim();
    return { kind: "field", name: normalizeIdentifier(name), type: parseType(type, file, issues) };
  });
}

function parseFunctions(text: string, file: string, issues: SkipIssue[]): RustFunction[] {
  const toplevel = (() => {
    const implRegex = /\bimpl\s+([A-Za-z_][A-Za-z0-9_]*)\s*\{/g;
    const ranges: Array<readonly [number, number]> = [];
    for (const match of text.matchAll(implRegex)) {
      const open = match.index + match[0].length - 1;
      const end = findMatching(text, open, "{", "}");
      if (end === -1) {
        issues.push({
          file,
          kind: "impl",
          snippet: String(match[1]),
          reason: "Could not parse impl block while stripping top-level functions.",
        });
        continue;
      }
      ranges.push([match.index, end + 1]);
    }
    if (ranges.length === 0) return text;
    ranges.sort((a, b) => b[0] - a[0]);
    let result = text;
    for (const [start, end] of ranges) {
      result = `${result.slice(0, start)}${result.slice(end)}`;
    }
    return result;
  })();

  const out: RustFunction[] = [];
  const fnRegex = /\bpub\s+fn\s+([A-Za-z_][A-Za-z0-9_]*)/g;
  for (const match of toplevel.matchAll(fnRegex)) {
    const name = match[1];
    if (!name) continue;
    const i = match.index + match[0].length;
    const trimmed = toplevel.slice(i).trimStart();
    const baseOffset = i + (toplevel.slice(i).length - trimmed.length);
    let p = baseOffset;
    let typeParams: string[] = [];
    if (toplevel[p] === "<") {
      const g = findMatching(toplevel, p, "<", ">");
      if (g === -1) continue;
      typeParams = parseGenericParamNames(toplevel.slice(p + 1, g), file, issues);
      p = g + 1;
    }
    p = skipWs(toplevel, p);
    if (toplevel[p] !== "(") continue;
    const paramsStart = p;
    const paramsEnd = findMatching(toplevel, paramsStart, "(", ")");
    if (paramsEnd === -1) continue;

    const paramsRaw = toplevel.slice(paramsStart + 1, paramsEnd);
    let q = paramsEnd + 1;
    q = skipWs(toplevel, q);
    let returnType = "void";
    let returnEnd = q;
    if (toplevel[q] === "-" && toplevel[q + 1] === ">") {
      q += 2;
      q = skipWs(toplevel, q);
      let r = q;
      for (; r < toplevel.length; r += 1) {
        if (toplevel[r] === "{") break;
      }
      returnType = normalizeTypeText(toplevel.slice(q, r));
      returnEnd = r;
    }
    const bodyStart = skipWs(toplevel, returnType === "void" ? q : returnEnd);
    if (toplevel[bodyStart] !== "{") continue;
    const bodyEnd = findMatching(toplevel, bodyStart, "{", "}");
    if (bodyEnd === -1) continue;
    const fn: RustFunction = {
      name: normalizeIdentifier(name),
      typeParams,
      params: parseParams(paramsRaw, file, issues),
      returnType: parseType(returnType, file, issues),
    };
    out.push(fn);
    void bodyEnd;
  }
  return out;
}

function parseStructs(text: string, file: string, issues: SkipIssue[]): RustStruct[] {
  const structs: RustStruct[] = [];
  const structRegex = /\bpub\s+struct\s+([A-Za-z_][A-Za-z0-9_]*)\s*(?:<([^>]*)>)?\s*\{/g;
  for (const match of text.matchAll(structRegex)) {
    const name = match[1];
    const genericRaw = match[2];
    if (!name) continue;
    const start = match.index + match[0].length - 1;
    const end = findMatching(text, start, "{", "}");
    if (end === -1) fail(`Unclosed struct body for ${name} in ${file}.`);
    const body = text.slice(start + 1, end);
    const fields: RustField[] = [];
    const fieldRegex = /\bpub\s+([A-Za-z_][A-Za-z0-9_]*)\s*:\s*([^,\n;]+)[,;]?/g;
    for (const fm of body.matchAll(fieldRegex)) {
      const fieldName = fm[1];
      const fieldType = fm[2];
      if (!fieldName || !fieldType) continue;
      fields.push({
        kind: "field",
        name: normalizeIdentifier(fieldName),
        type: parseType(fieldType, file, issues),
      });
    }
    structs.push({
      name: normalizeIdentifier(name),
      typeParams: genericRaw ? parseGenericParamNames(genericRaw, file, issues) : [],
      fields,
      methods: [],
      constructorMethod: undefined,
    });
  }
  return structs;
}

function parseEnums(text: string, file: string, issues: SkipIssue[]): RustEnum[] {
  const enums: RustEnum[] = [];
  const enumRegex = /\bpub\s+enum\s+([A-Za-z_][A-Za-z0-9_]*)\s*(?:<([^>]*)>)?\s*\{/g;
  for (const match of text.matchAll(enumRegex)) {
    const name = match[1];
    const genericRaw = match[2];
    if (!name) continue;
    const start = match.index + match[0].length - 1;
    const end = findMatching(text, start, "{", "}");
    if (end === -1) fail(`Unclosed enum body for ${name} in ${file}.`);
    const body = text.slice(start + 1, end);
    const variants = body
      .split(",")
      .map((entry) => normalizeTypeText(entry))
      .map((entry) => entry.replace(/[\r\n]+/g, " ").trim())
      .map((entry) => entry.replace(/\s+(=|:).*$/g, "").trim())
      .filter((entry) => entry.length > 0 && entry !== "{")
      .map((entry) => normalizeIdentifier(entry));
    if (variants.length === 0) {
      issues.push({
        file,
        kind: "enum",
        snippet: name,
        reason: "Enum has no parseable variants.",
      });
    }
    enums.push({
      name: normalizeIdentifier(name),
      typeParams: genericRaw ? parseGenericParamNames(genericRaw, file, issues) : [],
      variants,
    });
  }
  return enums;
}

function parseTraitMethods(body: string, file: string, issues: SkipIssue[]): RustTraitMethod[] {
  const methods: RustTraitMethod[] = [];
  const fnRegex = /\bfn\s+([A-Za-z_][A-Za-z0-9_]*)/g;
  for (const match of body.matchAll(fnRegex)) {
    const rawName = match[1];
    if (!rawName) continue;
    const name = normalizeIdentifier(rawName);
    let p = match.index + match[0].length;
    p = skipWs(body, p);

    let methodTypeParams: string[] = [];
    if (body[p] === "<") {
      const genEnd = findMatching(body, p, "<", ">");
      if (genEnd === -1) {
        issues.push({
          file,
          kind: "trait-method",
          snippet: name,
          reason: "Could not parse trait method generic parameters.",
        });
        continue;
      }
      methodTypeParams = parseGenericParamNames(body.slice(p + 1, genEnd), file, issues);
      p = genEnd + 1;
      p = skipWs(body, p);
    }

    if (body[p] !== "(") {
      issues.push({
        file,
        kind: "trait-method",
        snippet: name,
        reason: "Trait method parameter list could not be parsed.",
      });
      continue;
    }
    const paramsStart = p;
    const paramsEnd = findMatching(body, paramsStart, "(", ")");
    if (paramsEnd === -1) {
      issues.push({
        file,
        kind: "trait-method",
        snippet: name,
        reason: "Unclosed trait method parameter list.",
      });
      continue;
    }
    const paramsRaw = body.slice(paramsStart + 1, paramsEnd);
    let q = skipWs(body, paramsEnd + 1);
    let returnType = "void";
    if (body[q] === "-" && body[q + 1] === ">") {
      q += 2;
      q = skipWs(body, q);
      let r = q;
      while (r < body.length && body[r] !== ";" && body[r] !== "{") r += 1;
      returnType = parseType(body.slice(q, r), file, issues);
      q = r;
    }
    if (body[q] === "{") {
      const endBody = findMatching(body, q, "{", "}");
      if (endBody === -1) {
        issues.push({
          file,
          kind: "trait-method",
          snippet: name,
          reason: "Unclosed trait method body.",
        });
      }
    }
    methods.push({
      name,
      typeParams: methodTypeParams,
      params: parseParams(paramsRaw, file, issues),
      returnType,
    });
  }
  return methods;
}

function parseTraits(text: string, file: string, issues: SkipIssue[]): RustTrait[] {
  const traits: RustTrait[] = [];
  const traitRegex = /\bpub\s+trait\s+([A-Za-z_][A-Za-z0-9_]*)/g;
  for (const match of text.matchAll(traitRegex)) {
    const rawName = match[1];
    if (!rawName) continue;
    const name = normalizeIdentifier(rawName);
    let p = match.index + match[0].length;
    p = skipWs(text, p);

    let traitTypeParams: string[] = [];
    if (text[p] === "<") {
      const genEnd = findMatching(text, p, "<", ">");
      if (genEnd === -1) {
        issues.push({
          file,
          kind: "trait",
          snippet: name,
          reason: "Could not parse trait generic parameters.",
        });
        continue;
      }
      traitTypeParams = parseGenericParamNames(text.slice(p + 1, genEnd), file, issues);
      p = genEnd + 1;
      p = skipWs(text, p);
    }

    let superTraits: RustType[] = [];
    if (text[p] === ":") {
      p += 1;
      p = skipWs(text, p);
      let s = p;
      while (s < text.length && text[s] !== "{") s += 1;
      if (s >= text.length) {
        issues.push({
          file,
          kind: "trait",
          snippet: name,
          reason: "Unclosed trait header while reading supertraits.",
        });
        continue;
      }
      superTraits = splitTopLevel(text.slice(p, s), "+")
        .map((entry) => parseType(entry, file, issues))
        .filter((entry) => entry.length > 0 && entry !== "unknown");
      p = s;
    }

    if (text[p] !== "{") {
      issues.push({
        file,
        kind: "trait",
        snippet: name,
        reason: "Trait body could not be parsed.",
      });
      continue;
    }
    const bodyEnd = findMatching(text, p, "{", "}");
    if (bodyEnd === -1) {
      issues.push({
        file,
        kind: "trait",
        snippet: name,
        reason: "Unclosed trait body.",
      });
      continue;
    }
    const body = text.slice(p + 1, bodyEnd);
    const associatedTypes = [...body.matchAll(/\btype\s+([A-Za-z_][A-Za-z0-9_]*)\b/g)]
      .map((m) => m[1])
      .filter((v): v is string => typeof v === "string")
      .map((v) => normalizeIdentifier(v));
    const assocSet = new Set<string>(associatedTypes);
    const typeParams = [...traitTypeParams, ...[...assocSet].filter((v) => !traitTypeParams.includes(v))];
    traits.push({
      name,
      typeParams,
      superTraits,
      methods: parseTraitMethods(body, file, issues),
    });
  }
  return traits;
}

function parseImpls(text: string, file: string, issues: SkipIssue[]): Map<string, RustFunction[]> {
  const methodsByTarget = new Map<string, RustFunction[]>();
  const implRegex = /\bimpl\s+([A-Za-z_][A-Za-z0-9_]*)\s*\{/g;
  for (const match of text.matchAll(implRegex)) {
    const target = match[1];
    if (!target) continue;
    const start = match.index + match[0].length - 1;
    const end = findMatching(text, start, "{", "}");
    if (end === -1) {
      issues.push({
        file,
        kind: "impl",
        snippet: String(target),
        reason: `Could not parse impl body for ${target}.`,
      });
      continue;
    }
    const body = text.slice(start + 1, end);
    const methods = parseFunctions(body, file, issues);
    if (methods.length > 0) methodsByTarget.set(target, methods);
  }
  return methodsByTarget;
}

function parseModuleDeclarations(text: string, file: string): ParsedModule {
  const source = stripCommentsAndAttrs(text);
  const skip: SkipIssue[] = [];
  const module: ParsedModule = {
    specName: "",
    source: file,
    moduleParts: [],
    consts: [],
    enums: [],
    structs: [],
    traits: [],
    functions: [],
    reexports: [],
    pendingMethods: new Map(),
    issues: skip,
  };
  const constRegex = /\bpub\s+const\s+([A-Za-z_][A-Za-z0-9_]*)\s*:\s*([^;]+);/g;
  for (const match of source.matchAll(constRegex)) {
    const name = match[1];
    const rawType = match[2];
    if (!name || !rawType) continue;
    module.consts.push({
      kind: "field",
      name: normalizeIdentifier(name),
      type: parseType(rawType, file, skip),
    });
  }
  module.functions = parseFunctions(source, file, skip);
  module.structs = parseStructs(source, file, skip);
  module.traits = parseTraits(source, file, skip);
  module.enums = parseEnums(source, file, skip);
  module.pendingMethods = parseImpls(source, file, skip);
  return module;
}

function collectModuleSourceFiles(filePath: string): readonly string[] {
  const srcDir = dirname(filePath);
  const text = readFileSync(filePath, "utf-8");
  const out: string[] = [];
  const modRegex = /\bpub\s+mod\s+([A-Za-z_][A-Za-z0-9_]*)\s*;/g;
  for (const match of text.matchAll(modRegex)) {
    const raw = match[1];
    if (!raw) continue;
    const direct = join(srcDir, `${raw}.rs`);
    const nested = join(srcDir, raw, "mod.rs");
    if (existsSync(direct)) out.push(direct);
    else if (existsSync(nested)) out.push(nested);
    else fail(`Could not resolve pub mod ${JSON.stringify(raw)} from ${filePath}.`);
  }
  return out;
}

function collectModulesLegacy(manifestPath: string): ParsedModule[] {
  const srcRoot = join(dirname(manifestPath), "src");
  const root = join(srcRoot, "lib.rs");
  if (!existsSync(root)) fail(`Missing library root ${root}.`);
  const out: ParsedModule[] = [];
  const seen = new Set<string>();

  const visit = (filePath: string, parts: readonly string[]): void => {
    const abs = resolve(filePath);
    if (seen.has(abs)) return;
    const source = readFileSync(abs, "utf-8");
    const module = parseModuleDeclarations(source, abs);
    module.moduleParts = [...parts];
    module.specName = moduleSpecifier("@tsuba/placeholder", parts);
    out.push(module);
    seen.add(abs);
    for (const child of collectModuleSourceFiles(abs)) {
      const file = basename(child);
      const modName = file === "mod.rs" ? basename(dirname(child)) : file.replace(/\.rs$/g, "");
      visit(child, [...parts, modName]);
    }
  };

  visit(root, []);
  return out;
}

function mapExtractedFunction(fn: RustFunction, file: string, issues: SkipIssue[]): RustFunction {
  return {
    name: normalizeIdentifier(fn.name),
    typeParams: [...(fn.typeParams ?? [])].map((p) => normalizeIdentifier(p)),
    params: fn.params.map((p) => ({
      kind: "field",
      name: normalizeIdentifier(p.name),
      type: parseType(p.type, file, issues),
    })),
    returnType: parseType(fn.returnType, file, issues),
  };
}

function mapExtractedModule(module: ExtractedModule): ParsedModule {
  const issues: SkipIssue[] = [...module.issues];
  const source = module.file;
  const structs: RustStruct[] = module.structs.map((s) => ({
    name: normalizeIdentifier(s.name),
    typeParams: [...(s.typeParams ?? [])].map((p) => normalizeIdentifier(p)),
    fields: s.fields.map((f) => ({
      kind: "field",
      name: normalizeIdentifier(f.name),
      type: parseType(f.type, source, issues),
    })),
    methods: [],
    constructorMethod: undefined,
  }));
  const parsed: ParsedModule = {
    specName: "",
    source,
    moduleParts: [...module.parts],
    consts: module.consts.map((c) => ({
      kind: "field",
      name: normalizeIdentifier(c.name),
      type: parseType(c.type, source, issues),
    })),
    enums: module.enums.map((e) => ({
      name: normalizeIdentifier(e.name),
      typeParams: [...(e.typeParams ?? [])].map((p) => normalizeIdentifier(p)),
      variants: e.variants.map((v) => normalizeIdentifier(v)),
    })),
    structs,
    traits: module.traits.map((t) => ({
      name: normalizeIdentifier(t.name),
      typeParams: [...(t.typeParams ?? [])].map((p) => normalizeIdentifier(p)),
      superTraits: t.superTraits.map((st) => parseType(st, source, issues)),
      methods: t.methods.map((m) => ({
        name: normalizeIdentifier(m.name),
        typeParams: [...(m.typeParams ?? [])].map((p) => normalizeIdentifier(p)),
        params: m.params.map((p) => ({
          kind: "field",
          name: normalizeIdentifier(p.name),
          type: parseType(p.type, source, issues),
        })),
        returnType: parseType(m.returnType, source, issues),
      })),
    })),
    functions: module.functions.map((f) => mapExtractedFunction(f, source, issues)),
    reexports: [...(module.reexports ?? [])]
      .map((r) => ({ name: normalizeIdentifier(r.name), source: normalizeTypeText(r.source) }))
      .sort((a, b) => {
        const byName = a.name.localeCompare(b.name);
        if (byName !== 0) return byName;
        return a.source.localeCompare(b.source);
      }),
    pendingMethods: new Map(
      module.pendingMethods.map((entry) => [
        normalizeIdentifier(entry.target),
        entry.methods.map((m) => mapExtractedFunction(m, source, issues)),
      ])
    ),
    issues,
  };
  return parsed;
}

function runRustExtractor(manifestPath: string): ExtractedOutput {
  const extractorManifest = resolve(
    dirname(fileURLToPath(import.meta.url)),
    "../rust-extractor/Cargo.toml"
  );
  const result = spawnSync(
    "cargo",
    ["run", "--quiet", "--manifest-path", extractorManifest, "--", manifestPath],
    { encoding: "utf-8" }
  );
  if (result.status !== 0) {
    fail(
      `tsubabindgen Rust extractor failed for ${manifestPath}:\n${`${result.stdout ?? ""}${result.stderr ?? ""}`.trim()}`
    );
  }
  const raw = result.stdout?.trim();
  if (!raw) fail(`tsubabindgen Rust extractor returned no output for ${manifestPath}.`);
  const parsed = JSON.parse(raw) as ExtractedOutput;
  if (parsed.schema !== 1) {
    fail(`Unsupported extractor schema ${String((parsed as { schema?: unknown }).schema)} (expected 1).`);
  }
  return parsed;
}

function collectModules(manifestPath: string): ParsedModule[] {
  const extracted = runRustExtractor(manifestPath);
  const modules = extracted.modules.map((m) => mapExtractedModule(m));
  if (modules.length > 0) {
    return modules;
  }
  if (process.env.TSUBABINDGEN_ALLOW_LEGACY === "1") {
    return collectModulesLegacy(manifestPath);
  }
  fail(
    `Rust extractor returned no modules for ${manifestPath}. Set TSUBABINDGEN_ALLOW_LEGACY=1 to debug with the legacy parser.`
  );
}

function moduleSpecifier(pkg: string, parts: readonly string[]): string {
  if (parts.length === 0) return `${pkg}/index.js`;
  return `${pkg}/${parts.join("/")}.js`;
}

function moduleJsName(parts: readonly string[]): string {
  return parts.length === 0 ? "index.js" : `${parts.join("/")}.js`;
}

function moduleDtsName(parts: readonly string[]): string {
  return parts.length === 0 ? "index.d.ts" : `${parts.join("/")}.d.ts`;
}

function rustPath(crateName: string, parts: readonly string[]): string {
  return [crateName, ...parts].join("::");
}

function attachMethods(modules: ParsedModule[]): void {
  const structByName = new Map<string, RustStruct>();
  for (const m of modules) {
    for (const s of m.structs) structByName.set(s.name, s);
  }
  for (const m of modules) {
    for (const [targetRaw, methods] of m.pendingMethods) {
      const target = normalizeIdentifier(targetRaw);
      const struct = structByName.get(target);
      if (!struct) continue;
      for (const mth of methods) {
        const isInstance = mth.params.length > 0 && isSelfLike(mth.params[0]?.name ?? "");
        const params = isInstance
          ? mth.params.slice(1).filter((p) => p.type !== "void")
          : mth.params.filter((p) => p.type !== "void");
        if (mth.name === "new" || mth.name === "new_") {
          struct.constructorMethod = {
            name: "new",
            kind: "constructor",
            typeParams: mth.typeParams,
            params,
            returnType: mth.returnType,
          };
          continue;
        }
        struct.methods.push({
          name: mth.name,
          kind: isInstance ? "instance" : "static",
          typeParams: mth.typeParams,
          params,
          returnType: mth.returnType,
        });
      }
    }
  }
}

function cloneAsConst(value: RustField, name: string): RustField {
  return { kind: "field", name, type: value.type };
}

function cloneAsEnum(value: RustEnum, name: string): RustEnum {
  return {
    name,
    typeParams: [...value.typeParams],
    variants: [...value.variants],
  };
}

function cloneAsStruct(value: RustStruct, name: string): RustStruct {
  return {
    name,
    typeParams: [...value.typeParams],
    fields: value.fields.map((f) => ({ kind: "field", name: f.name, type: f.type })),
    methods: value.methods.map((m) => ({
      name: m.name,
      kind: m.kind,
      typeParams: [...m.typeParams],
      params: m.params.map((p) => ({ kind: "field", name: p.name, type: p.type })),
      returnType: m.returnType,
    })),
    constructorMethod: value.constructorMethod
      ? {
          name: value.constructorMethod.name,
          kind: value.constructorMethod.kind,
          typeParams: [...value.constructorMethod.typeParams],
          params: value.constructorMethod.params.map((p) => ({ kind: "field", name: p.name, type: p.type })),
          returnType: value.constructorMethod.returnType,
        }
      : undefined,
  };
}

function cloneAsTrait(value: RustTrait, name: string): RustTrait {
  return {
    name,
    typeParams: [...value.typeParams],
    superTraits: [...value.superTraits],
    methods: value.methods.map((m) => ({
      name: m.name,
      typeParams: [...m.typeParams],
      params: m.params.map((p) => ({ kind: "field", name: p.name, type: p.type })),
      returnType: m.returnType,
    })),
  };
}

function cloneAsFunction(value: RustFunction, name: string): RustFunction {
  return {
    name,
    typeParams: [...value.typeParams],
    params: value.params.map((p) => ({ kind: "field", name: p.name, type: p.type })),
    returnType: value.returnType,
  };
}

function hasDeclarationNamed(module: ParsedModule, name: string): boolean {
  if (module.consts.some((d) => d.name === name)) return true;
  if (module.enums.some((d) => d.name === name)) return true;
  if (module.structs.some((d) => d.name === name)) return true;
  if (module.traits.some((d) => d.name === name)) return true;
  if (module.functions.some((d) => d.name === name)) return true;
  return false;
}

function findModuleByParts(modules: readonly ParsedModule[], parts: readonly string[]): ParsedModule | undefined {
  const key = parts.join("::");
  return modules.find((m) => m.moduleParts.join("::") === key);
}

function resolveReexportSourceModule(
  modules: readonly ParsedModule[],
  from: ParsedModule,
  sourcePath: readonly string[]
): { readonly module: ParsedModule; readonly symbol: string } | undefined {
  if (sourcePath.length === 0) return undefined;
  const [head, ...rest] = sourcePath;
  if (!head) return undefined;

  let baseParts: string[];
  let lookupParts: string[];

  if (head === "crate") {
    baseParts = [];
    lookupParts = rest;
  } else if (head === "self") {
    baseParts = [...from.moduleParts];
    lookupParts = rest;
  } else if (head === "super") {
    baseParts = from.moduleParts.length === 0 ? [] : from.moduleParts.slice(0, -1);
    lookupParts = rest;
  } else {
    baseParts = [...from.moduleParts];
    lookupParts = [...sourcePath];
  }

  if (lookupParts.length === 0) return undefined;
  const symbol = lookupParts[lookupParts.length - 1]!;
  const moduleParts = [...baseParts, ...lookupParts.slice(0, -1)];
  const module = findModuleByParts(modules, moduleParts);
  if (!module) return undefined;
  return { module, symbol };
}

function addReexportedDeclaration(
  toModule: ParsedModule,
  fromModule: ParsedModule,
  sourceSymbol: string,
  exportedName: string
): boolean {
  if (hasDeclarationNamed(toModule, exportedName)) return true;

  const constDecl = fromModule.consts.find((d) => d.name === sourceSymbol);
  if (constDecl) {
    toModule.consts.push(cloneAsConst(constDecl, exportedName));
    return true;
  }

  const enumDecl = fromModule.enums.find((d) => d.name === sourceSymbol);
  if (enumDecl) {
    toModule.enums.push(cloneAsEnum(enumDecl, exportedName));
    return true;
  }

  const structDecl = fromModule.structs.find((d) => d.name === sourceSymbol);
  if (structDecl) {
    toModule.structs.push(cloneAsStruct(structDecl, exportedName));
    return true;
  }

  const traitDecl = fromModule.traits.find((d) => d.name === sourceSymbol);
  if (traitDecl) {
    toModule.traits.push(cloneAsTrait(traitDecl, exportedName));
    return true;
  }

  const fnDecl = fromModule.functions.find((d) => d.name === sourceSymbol);
  if (fnDecl) {
    toModule.functions.push(cloneAsFunction(fnDecl, exportedName));
    return true;
  }

  return false;
}

function sortModuleDeclarations(module: ParsedModule): void {
  module.consts.sort((a, b) => a.name.localeCompare(b.name));
  module.enums.sort((a, b) => a.name.localeCompare(b.name));
  module.structs.sort((a, b) => a.name.localeCompare(b.name));
  module.traits.sort((a, b) => a.name.localeCompare(b.name));
  module.functions.sort((a, b) => a.name.localeCompare(b.name));
}

function applyReexports(modules: ParsedModule[]): void {
  for (const module of modules) {
    for (const reexport of module.reexports) {
      const segments = reexport.source.split("::").filter((s) => s.length > 0);
      const resolved = resolveReexportSourceModule(modules, module, segments);
      if (!resolved) {
        module.issues.push({
          file: module.source,
          kind: "reexport",
          snippet: `${reexport.name} <- ${reexport.source}`,
          reason: "Could not resolve re-export source module path.",
        });
        continue;
      }
      const ok = addReexportedDeclaration(module, resolved.module, resolved.symbol, reexport.name);
      if (!ok) {
        module.issues.push({
          file: module.source,
          kind: "reexport",
          snippet: `${reexport.name} <- ${reexport.source}`,
          reason: "Could not resolve re-exported symbol in source module.",
        });
      }
    }
    sortModuleDeclarations(module);
  }
}

function collectMarkerTypes(modules: readonly ParsedModule[]): string[] {
  const tokens = new Set<string>();
  const emitText = (text: string): void => {
    const matches = text.match(/\b[A-Za-z_][A-Za-z0-9_]*\b/g) ?? [];
    for (const token of matches) {
      if (MARKER_TYPES.has(token)) tokens.add(token);
    }
  };
  for (const module of modules) {
    for (const c of module.consts) {
      emitText(c.type);
    }
    for (const s of module.structs) {
      for (const f of s.fields) emitText(f.type);
      if (s.constructorMethod) {
        emitText(s.constructorMethod.returnType);
        for (const p of s.constructorMethod.params) emitText(p.type);
      }
      for (const m of s.methods) {
        emitText(m.returnType);
        for (const p of m.params) emitText(p.type);
      }
    }
    for (const e of module.enums) emitText(e.name);
    for (const t of module.traits) {
      for (const st of t.superTraits) emitText(st);
      for (const m of t.methods) {
        emitText(m.returnType);
        const first = m.params.at(0);
        if (first?.name === "&self") emitText("ref<this>");
        if (first?.name === "&mut self") emitText("mutref<this>");
        for (const p of m.params) emitText(p.type);
      }
    }
    for (const f of module.functions) {
      emitText(f.returnType);
      for (const p of f.params) emitText(p.type);
    }
  }
  return [...tokens].sort((a, b) => a.localeCompare(b)).filter((name) => !JS_KEYWORDS.has(name));
}

function emitDts(module: ParsedModule): string {
  const lines: string[] = [];
  lines.push("// Generated by tsubabindgen (v0)", "");
  lines.push(...module.consts.map((c) => `export const ${c.name}: ${c.type};`));

  for (const e of module.enums) {
    const enumTypeParams = e.typeParams.length > 0 ? `<${e.typeParams.join(", ")}>` : "";
    lines.push(`export declare class ${e.name}${enumTypeParams} {`);
    lines.push("  private constructor();");
    for (const v of e.variants) {
      lines.push(`  static readonly ${v}: ${e.name}${enumTypeParams};`);
    }
    lines.push("}");
    lines.push("");
  }

  for (const t of module.traits) {
    const traitTypeParams = t.typeParams.length > 0 ? `<${t.typeParams.join(", ")}>` : "";
    const extendsClause = t.superTraits.length > 0 ? ` extends ${t.superTraits.join(", ")}` : "";
    lines.push(`export interface ${t.name}${traitTypeParams}${extendsClause} {`);
    for (const m of t.methods) {
      const methodTypeParams = m.typeParams.length > 0 ? `<${m.typeParams.join(", ")}>` : "";
      const params = [...m.params];
      const first = params.at(0);
      const hasSelf = isSelfLike(first?.name ?? "");
      const thisParam =
        first?.name === "&mut self"
          ? "this: mutref<this>"
          : first?.name === "&self"
            ? "this: ref<this>"
            : first?.name === "self"
              ? "this: this"
              : undefined;
      const restParams = hasSelf ? params.slice(1) : params;
      const args = [...(thisParam ? [thisParam] : []), ...restParams.map((p) => `${p.name}: ${p.type}`)].join(", ");
      lines.push(`  ${m.name}${methodTypeParams}(${args}): ${m.returnType};`);
    }
    lines.push("}");
    lines.push("");
  }

  for (const s of module.structs) {
    const structTypeParams = s.typeParams.length > 0 ? `<${s.typeParams.join(", ")}>` : "";
    lines.push(`export declare class ${s.name}${structTypeParams} {`);
    for (const field of s.fields) {
      lines.push(`  ${field.name}: ${field.type};`);
    }
    if (s.constructorMethod) {
      const ctorTypeParams =
        s.constructorMethod.typeParams.length > 0 ? `<${s.constructorMethod.typeParams.join(", ")}>` : "";
      lines.push(
        `  constructor${ctorTypeParams}(${s.constructorMethod.params.map((p) => `${p.name}: ${p.type}`).join(", ")});`
      );
    }
    for (const m of s.methods) {
      const methodTypeParams = m.typeParams.length > 0 ? `<${m.typeParams.join(", ")}>` : "";
      const args = m.params.map((p) => `${p.name}: ${p.type}`).join(", ");
      if (m.kind === "instance") {
        lines.push(`  ${m.name}${methodTypeParams}(${args}): ${m.returnType};`);
      } else {
        lines.push(`  static ${m.name}${methodTypeParams}(${args}): ${m.returnType};`);
      }
    }
    lines.push("}");
    lines.push("");
  }

  for (const f of module.functions) {
    const fnTypeParams = f.typeParams.length > 0 ? `<${f.typeParams.join(", ")}>` : "";
    const args = f.params.map((p) => `${p.name}: ${p.type}`).join(", ");
    lines.push(`export function ${f.name}${fnTypeParams}(${args}): ${f.returnType};`);
  }

  const markerTypes = collectMarkerTypes([module]).filter((name) => !name.startsWith("__"));
  if (markerTypes.length > 0) {
    lines.unshift(`import type { ${markerTypes.join(", ")} } from "@tsuba/core/types.js";`, "");
  }

  return lines.join("\n").trimEnd() + "\n";
}

function makePackageJson(packageName: string, version: string, entrypoints: readonly string[]): string {
  const exports: Record<string, { types: string; default: string }> = {
    ".": { types: "./index.d.ts", default: "./index.js" },
  };
  for (const entry of entrypoints) {
    exports[`./${entry}`] = {
      types: `./${entry.replace(/\.js$/g, ".d.ts")}`,
      default: `./${entry}`,
    };
  }
  const files = ["index.d.ts", "index.js", "tsuba.bindings.json", "README.md", "package.json"];
  for (const entry of entrypoints) {
    files.push(entry);
    files.push(entry.replace(/\.js$/g, ".d.ts"));
  }
  const pkg = {
    name: packageName,
    version,
    type: "module",
    main: "./index.js",
    types: "./index.d.ts",
    exports,
    files,
  };
  return `${JSON.stringify(pkg, null, 2)}\n`;
}

function skipWs(text: string, start: number): number {
  let i = start;
  while (i < text.length) {
    const ch = text.charCodeAt(i);
    if (ch === 10 || ch === 13 || ch === 32 || ch === 9) {
      i += 1;
      continue;
    }
    break;
  }
  return i;
}

function moduleForRustPath(modules: readonly ParsedModule[], crateName: string, rustPath: string): ParsedModule {
  if (rustPath === crateName) {
    const root = modules.find((m) => m.moduleParts.length === 0);
    if (!root) fail(`Could not find root module for rust path ${rustPath}.`);
    return root;
  }
  const targetParts = rustPath.slice(crateName.length + 2).split("::");
  const target = modules.find((m) => m.moduleParts.join("::") === targetParts.join("::"));
  if (!target) fail(`Could not find module for ${rustPath}.`);
  return target;
}

function collectSkipIssues(modules: readonly ParsedModule[], crateRoot?: string): readonly SkipIssue[] {
  const normalizeIssueFile = (value: string): string => {
    if (!crateRoot) return normalizePath(value);
    const rel = normalizePath(relative(crateRoot, resolve(value)));
    if (rel.length === 0 || rel.startsWith("../")) return normalizePath(value);
    return rel;
  };
  const seen = new Set<string>();
  const out: SkipIssue[] = [];
  for (const module of modules) {
    for (const issue of module.issues) {
      const file = normalizeIssueFile(issue.file);
      const key = `${file}\u0000${issue.kind}\u0000${issue.snippet}\u0000${issue.reason}`;
      if (seen.has(key)) continue;
      seen.add(key);
      out.push({ ...issue, file });
    }
  }
  out.sort((a, b) => {
    const byFile = a.file.localeCompare(b.file);
    if (byFile !== 0) return byFile;
    const byKind = a.kind.localeCompare(b.kind);
    if (byKind !== 0) return byKind;
    const bySnippet = a.snippet.localeCompare(b.snippet);
    if (bySnippet !== 0) return bySnippet;
    return a.reason.localeCompare(b.reason);
  });
  return out;
}

function runCargoMetadata(manifestPath: string): unknown {
  const result = spawnSync("cargo", ["metadata", "--format-version", "1", "--manifest-path", manifestPath], {
    encoding: "utf-8",
  });
  if (result.status !== 0) {
    fail(
      `cargo metadata failed for ${manifestPath}:\n${`${result.stdout ?? ""}${result.stderr ?? ""}`.trim()}`
    );
  }
  const raw = result.stdout;
  if (!raw) fail(`cargo metadata returned no output for ${manifestPath}.`);
  return JSON.parse(raw) as unknown;
}

export function runGenerate(opts: GenerateOptions): void {
  const absManifest = resolve(opts.manifestPath);
  const outDir = resolve(opts.outDir);
  const metadata = runCargoMetadata(absManifest) as {
    readonly packages?: readonly {
      readonly name: string;
      readonly version: string;
      readonly manifest_path: string;
      readonly targets?: readonly { readonly name: string; readonly kind?: readonly string[] }[];
    }[];
  };
  const pkg = metadata.packages?.find((entry) => resolve(entry.manifest_path) === absManifest);
  if (!pkg) fail(`Could not find package for manifest ${absManifest} in cargo metadata output.`);

  const libTarget = (pkg.targets ?? []).find((target) =>
    (target.kind ?? []).includes("lib")
  );
  if (!libTarget) fail(`Could not find a lib target in manifest ${absManifest}.`);
  const crateName = libTarget.name;
  const chosenPackageName = opts.packageName ?? `@tsuba/${pkg.name}`;
  const version = pkg.version;

  rmSync(outDir, { recursive: true, force: true });
  ensureDir(outDir);

  const modules = collectModules(absManifest);
  attachMethods(modules);
  applyReexports(modules);
  const skipIssues = collectSkipIssues(modules, dirname(absManifest));

  const moduleEntries: { spec: string; jsName: string; rustPath: string; dtsName: string }[] = [];
  for (const module of modules) {
    const jsName = moduleJsName(module.moduleParts);
    const dtsName = moduleDtsName(module.moduleParts);
    moduleEntries.push({
      spec: moduleSpecifier(chosenPackageName, module.moduleParts),
      jsName,
      rustPath: rustPath(crateName, module.moduleParts),
      dtsName,
    });
  }
  moduleEntries.sort((a, b) => a.spec.localeCompare(b.spec));

  for (const entry of moduleEntries) {
    const outJs = join(outDir, entry.jsName);
    const outDts = join(outDir, entry.dtsName);
    const module = moduleForRustPath(modules, crateName, entry.rustPath);
    ensureDir(dirname(outDts));
    writeFileSync(outJs, MANIFEST_TEMPLATE, "utf-8");
    writeFileSync(outDts, emitDts(module), "utf-8");
  }

  const modulesMap: Record<string, string> = {};
  for (const entry of moduleEntries) modulesMap[entry.spec] = entry.rustPath;
  const manifest: GenerateBindings = {
    schema: 1,
    kind: "crate",
    crate: {
      name: crateName,
      package: pkg.name,
      ...(opts.bundleCrate ? { path: "./crate" } : { version }),
    },
    modules: modulesMap,
  };
  writeFileSync(join(outDir, "tsuba.bindings.json"), `${JSON.stringify(manifest, null, 2)}\n`, "utf-8");

  const entryPaths = moduleEntries.map((entry) => entry.jsName).sort((a, b) => a.localeCompare(b));
  const pkgVersion = version;
  writeFileSync(join(outDir, "package.json"), makePackageJson(chosenPackageName, pkgVersion, entryPaths), "utf-8");
  writeFileSync(join(outDir, "README.md"), `# ${chosenPackageName}\n\nGenerated by tsubabindgen.\n`, "utf-8");
  writeFileSync(
    join(outDir, "tsubabindgen.report.json"),
    `${JSON.stringify({ schema: 1, skipped: skipIssues }, null, 2)}\n`,
    "utf-8"
  );

  if (opts.bundleCrate) {
    copyDir(dirname(absManifest), join(outDir, "crate"));
  }
}
